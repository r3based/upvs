from __future__ import annotations

import json
import logging
import re
import time
from typing import Dict, List

import requests
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from .config import get_settings
from .db import Database
from .faiss_store import FaissStore

settings = get_settings()
logger = logging.getLogger("upvs.api")
logging.basicConfig(level=logging.INFO)

app = FastAPI(title="UPVS API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

db = Database(settings)
faiss_store = FaissStore(settings)


class SearchRequest(BaseModel):
    query: str
    top_k: int = Field(default=8, ge=1, le=50)


class ContextRequest(BaseModel):
    query: str
    top_k: int = Field(default=8, ge=1, le=50)
    tables_window: int = Field(default=2, ge=0, le=10)


class RagRequest(BaseModel):
    query: str
    top_k: int = Field(default=8, ge=1, le=50)
    tables_window: int = Field(default=2, ge=0, le=10)
    temperature: float = Field(default=0.2, ge=0.0, le=1.0)
    max_tokens: int = Field(default=800, ge=64, le=2048)


@app.on_event("startup")
def on_startup() -> None:
    db.init_schema()


@app.get("/health")
def health() -> Dict[str, str]:
    return {"status": "ok"}


@app.get("/pages")
def list_pages(query: str = "", limit: int = 20, offset: int = 0) -> Dict[str, object]:
    if query:
        rows = db.fetch_all(
            """
            SELECT page_id, url, title, fetched_at
            FROM pages
            WHERE title ILIKE %s
            ORDER BY fetched_at DESC NULLS LAST
            LIMIT %s OFFSET %s
            """,
            (f"%{query}%", limit, offset),
        )
    else:
        rows = db.fetch_all(
            """
            SELECT page_id, url, title, fetched_at
            FROM pages
            ORDER BY fetched_at DESC NULLS LAST
            LIMIT %s OFFSET %s
            """,
            (limit, offset),
        )
    return {"items": rows}


@app.get("/pages/{page_id}")
def get_page(page_id: str) -> Dict[str, object]:
    page = db.fetch_one(
        """
        SELECT page_id, url, title, parent_url, breadcrumbs, toc, fetched_at, http_status, content_hash
        FROM pages
        WHERE page_id = %s
        """,
        (page_id,),
    )
    if not page:
        raise HTTPException(status_code=404, detail="–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return page


@app.get("/pages/{page_id}/blocks")
def get_page_blocks(page_id: str) -> Dict[str, object]:
    page = db.fetch_one("SELECT page_id, url, title FROM pages WHERE page_id = %s", (page_id,))
    if not page:
        raise HTTPException(status_code=404, detail="–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    text_blocks = db.fetch_all(
        """
        SELECT chunk_id, source_order, section_path, text
        FROM text_chunks
        WHERE page_id = %s
        """,
        (page_id,),
    )
    table_blocks = db.fetch_all(
        """
        SELECT table_id, source_order, section_path, caption, columns, rows
        FROM tables
        WHERE page_id = %s
        """,
        (page_id,),
    )
    blocks: List[Dict[str, object]] = []
    for row in text_blocks:
        blocks.append(
            {
                "kind": "text",
                "chunk_id": row["chunk_id"],
                "source_order": row["source_order"],
                "section_path": row["section_path"],
                "text": row["text"],
            }
        )
    for row in table_blocks:
        blocks.append(
            {
                "kind": "table",
                "table_id": row["table_id"],
                "source_order": row["source_order"],
                "section_path": row["section_path"],
                "caption": row["caption"],
                "columns": row["columns"],
                "rows": row["rows"],
            }
        )
    blocks.sort(key=lambda item: item["source_order"])
    return {"page": page, "blocks": blocks}


@app.get("/pages/{page_id}/neighbors")
def get_neighbors(page_id: str, depth: int = 1, limit: int = 20) -> Dict[str, object]:
    page = db.fetch_one("SELECT url FROM pages WHERE page_id = %s", (page_id,))
    if not page:
        raise HTTPException(status_code=404, detail="–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    url = page["url"]
    outgoing = db.fetch_all(
        "SELECT to_url FROM edges WHERE from_url = %s LIMIT %s", (url, limit)
    )
    incoming = db.fetch_all(
        "SELECT from_url FROM edges WHERE to_url = %s LIMIT %s", (url, limit)
    )
    urls = {row["to_url"] for row in outgoing} | {row["from_url"] for row in incoming}
    resolved = []
    if urls:
        resolved = db.fetch_all(
            "SELECT page_id, url, title FROM pages WHERE url = ANY(%s)", (list(urls),)
        )
    return {
        "depth": depth,
        "outgoing": outgoing,
        "incoming": incoming,
        "resolved": resolved,
    }


@app.get("/navigation/tree")
def get_navigation_tree() -> Dict[str, object]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ä–µ–≤–æ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ parent_url"""
    all_pages = db.fetch_all(
        """
        SELECT page_id, url, title, parent_url
        FROM pages
        WHERE title IS NOT NULL
        ORDER BY url
        """,
        (),
    )
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    pages_by_url: Dict[str, Dict[str, object]] = {}
    pages_by_id: Dict[str, Dict[str, object]] = {}
    for page in all_pages:
        url = page["url"]
        page_id = page["page_id"]
        pages_by_url[url] = page
        pages_by_id[page_id] = page
        page["children"] = []
    
    # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ
    root_pages = []
    for page in all_pages:
        parent_url = page.get("parent_url")
        if parent_url and parent_url in pages_by_url:
            parent = pages_by_url[parent_url]
            if "children" not in parent:
                parent["children"] = []
            parent["children"].append(page)
        else:
            root_pages.append(page)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–µ—Ç–µ–π –ø–æ title
    def sort_children(node: Dict[str, object]) -> None:
        if "children" in node and node["children"]:
            node["children"].sort(key=lambda x: x.get("title", "") or "")
            for child in node["children"]:
                sort_children(child)
    
    for root in root_pages:
        sort_children(root)
    
    return {"tree": root_pages}


@app.get("/navigation/page/{page_id}")
def get_page_navigation(page_id: str) -> Dict[str, object]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–≤–∏–≥–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: —Ä–æ–¥–∏—Ç–µ–ª–∏, —Å–æ—Å–µ–¥–∏, –¥–µ—Ç–∏"""
    page = db.fetch_one(
        """
        SELECT page_id, url, title, parent_url, breadcrumbs
        FROM pages
        WHERE page_id = %s
        """,
        (page_id,),
    )
    if not page:
        raise HTTPException(status_code=404, detail="–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
    parent = None
    if page.get("parent_url"):
        parent = db.fetch_one(
            "SELECT page_id, url, title FROM pages WHERE url = %s",
            (page["parent_url"],),
        )
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–¥–µ—Ç–∏ —Ç–æ–≥–æ –∂–µ —Ä–æ–¥–∏—Ç–µ–ª—è)
    siblings = []
    if page.get("parent_url"):
        siblings = db.fetch_all(
            """
            SELECT page_id, url, title
            FROM pages
            WHERE parent_url = %s AND page_id != %s
            ORDER BY title
            """,
            (page["parent_url"], page_id),
        )
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    children = db.fetch_all(
        """
        SELECT page_id, url, title
        FROM pages
        WHERE parent_url = %s
        ORDER BY title
        """,
        (page["url"],),
    )
    
    return {
        "current": {
            "page_id": page["page_id"],
            "url": page["url"],
            "title": page["title"],
        },
        "parent": parent,
        "siblings": siblings,
        "children": children,
    }


def _boost_score_by_keywords(score: float, text: str, title: str, query: str) -> float:
    """–£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç score –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–µ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""
    query_lower = query.lower()
    query_words = set(query_lower.split())
    
    text_lower = (text or "").lower()
    title_lower = (title or "").lower()
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    text_matches = sum(1 for word in query_words if word in text_lower)
    title_matches = sum(1 for word in query_words if word in title_lower)
    
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º score –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    boost = 0.0
    if title_matches > 0:
        boost += 0.15 * title_matches  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∞–∂–Ω–µ–µ
    if text_matches > 0:
        boost += 0.05 * min(text_matches, 3)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤–ª–∏—è–Ω–∏–µ
    
    return min(score + boost, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º–æ–º 1.0


@app.post("/search")
def search(req: SearchRequest) -> Dict[str, object]:
    start = time.perf_counter()
    try:
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º top_k –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
        semantic_hits = faiss_store.search(req.query, min(req.top_k * 2, 50))
    except FileNotFoundError as exc:
        raise HTTPException(status_code=500, detail=str(exc)) from exc
    
    page_ids = {hit.page_id for hit in semantic_hits}
    titles: Dict[str, str] = {}
    if page_ids:
        rows = db.fetch_all(
            "SELECT page_id, title FROM pages WHERE page_id = ANY(%s)", (list(page_ids),)
        )
        titles = {row["page_id"]: row.get("title") for row in rows}
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–±–ª–∏—Ü–∞—Ö –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    table_captions: Dict[str, List[str]] = {}
    if page_ids:
        table_rows = db.fetch_all(
            """
            SELECT DISTINCT page_id, caption
            FROM tables
            WHERE page_id = ANY(%s) AND caption IS NOT NULL
            """,
            (list(page_ids),),
        )
        for row in table_rows:
            page_id = row["page_id"]
            if page_id not in table_captions:
                table_captions[page_id] = []
            table_captions[page_id].append(row.get("caption", ""))
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –±—É—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    boosted_hits = []
    for hit in semantic_hits:
        title = titles.get(hit.page_id, "")
        page_tables = " ".join(table_captions.get(hit.page_id, []))
        combined_text = f"{title} {page_tables} {hit.text_preview}"
        
        boosted_score = _boost_score_by_keywords(
            hit.score, combined_text, title, req.query
        )
        boosted_hits.append((boosted_score, hit))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–≤–æ–º—É score –∏ –±–µ—Ä–µ–º top_k
    boosted_hits.sort(key=lambda x: x[0], reverse=True)
    top_hits = [hit for _, hit in boosted_hits[:req.top_k]]
    
    duration = time.perf_counter() - start
    logger.info("search duration=%.3fs query=%s", duration, req.query)

    result = []
    for hit in top_hits:
        result.append(
            {
                "chunk_id": hit.chunk_id,
                "page_id": hit.page_id,
                "url": hit.url,
                "score": hit.score,
                "section_path": hit.section_path,
                "text_preview": hit.text_preview,
                "title": titles.get(hit.page_id),
            }
        )
    return {"hits": result, "duration": duration}


def _collect_tables(page_id: str, source_order: int, window: int) -> List[Dict[str, object]]:
    tables = db.fetch_all(
        """
        SELECT table_id, source_order, caption, columns, rows
        FROM tables
        WHERE page_id = %s
        """,
        (page_id,),
    )
    if not tables:
        return []
    if window == 0:
        nearest = min(tables, key=lambda t: abs(t["source_order"] - source_order))
        return [nearest]
    return [t for t in tables if abs(t["source_order"] - source_order) <= window]


@app.post("/context")
def context(req: ContextRequest) -> Dict[str, object]:
    try:
        hits = faiss_store.search(req.query, req.top_k)
    except FileNotFoundError as exc:
        raise HTTPException(status_code=500, detail=str(exc)) from exc
    sources = []
    for hit in hits:
        chunk = db.fetch_one(
            """
            SELECT chunk_id, page_id, section_path, text, source_order
            FROM text_chunks
            WHERE chunk_id = %s
            """,
            (hit.chunk_id,),
        )
        if not chunk:
            continue
        page = db.fetch_one(
            "SELECT page_id, url, title FROM pages WHERE page_id = %s", (chunk["page_id"],)
        )
        tables = _collect_tables(chunk["page_id"], chunk["source_order"], req.tables_window)
        sources.append(
            {
                "page_id": chunk["page_id"],
                "url": page.get("url") if page else hit.url,
                "title": page.get("title") if page else None,
                "chunk_id": chunk["chunk_id"],
                "score": hit.score,
                "section_path": chunk["section_path"],
                "text": chunk["text"],
                "tables": tables,
            }
        )
    return {"sources": sources}


def _format_tables(tables: List[Dict[str, object]]) -> str:
    parts: List[str] = []
    for table in tables:
        caption = table.get("caption") or "–¢–∞–±–ª–∏—Ü–∞"
        columns = table.get("columns") or []
        rows = table.get("rows") or []
        parts.append(f"–¢–ê–ë–õ–ò–¶–ê: {caption}")
        if columns and len(columns) <= 10 and len(rows) <= 20:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ markdown —Ç–∞–±–ª–∏—Ü—É
            header = "| " + " | ".join(str(col) for col in columns) + " |"
            sep = "|" + "|".join([" --- " for _ in columns]) + "|"
            parts.append(header)
            parts.append(sep)
            for row in rows:
                row_str = "| " + " | ".join(str(cell) for cell in row) + " |"
                parts.append(row_str)
        else:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü –∏—Å–ø–æ–ª—å–∑—É–µ–º JSON
            parts.append(f"–ö–æ–ª–æ–Ω–∫–∏: {', '.join(str(c) for c in columns)}")
            parts.append(f"–°—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö: {len(rows)}")
            if rows:
                parts.append("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:")
                for i, row in enumerate(rows[:5]):
                    parts.append(f"  –°—Ç—Ä–æ–∫–∞ {i+1}: {dict(zip(columns, row))}")
    return "\n".join(parts)


@app.post("/rag")
def rag(req: RagRequest) -> Dict[str, object]:
    try:
        retrieval_start = time.perf_counter()
        context_payload = context(ContextRequest(query=req.query, top_k=req.top_k, tables_window=req.tables_window))
        retrieval_duration = time.perf_counter() - retrieval_start
        logger.info("context duration=%.3fs query=%s", retrieval_duration, req.query)

        sources = context_payload.get("sources", [])
        if not sources:
            return {"answer": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.", "sources": [], "error": None}

        system_prompt = (
            "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫—É UPVS (–£–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–µ –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ–ª—å–Ω–æ–π –°—Ç–æ–∏–º–æ—Å—Ç–∏). "
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. "
            "\n\n"
            "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê (–ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∫–æ –í–°–ï–ú —Ç–∞–±–ª–∏—Ü–∞–º): "
            "- –í –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –ù–ï–°–ö–û–õ–¨–ö–û –ø–æ—Ö–æ–∂–∏—Ö —Ç–∞–±–ª–∏—Ü —Å –†–ê–ó–ù–´–ú–ò –Ω–æ–º–µ—Ä–∞–º–∏\n"
            "- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ - –ü–ï–†–í–´–ô –∏—Å—Ç–æ—á–Ω–∏–∫ –æ–±—ã—á–Ω–æ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π\n"
            "- –í–ù–ò–ú–ê–¢–ï–õ–¨–ù–û —Å—Ä–∞–≤–Ω–∏–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –≤–æ–ø—Ä–æ—Å–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –¢–û–ß–ù–û —Å–æ–≤–ø–∞–¥–∞—Ç—å\n"
            "- –ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –∑–¥–∞–Ω–∏—è –∏–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞, "
            "–∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–∞–±–ª–∏—Ü—É, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –≠–¢–ò –ñ–ï —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏\n"
            "- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã, –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —ç—Ç—É —Ç–∞–±–ª–∏—Ü—É\n"
            "- –ù–ï –ü–£–¢–ê–ô —Ä–∞–∑–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã - –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—Ö–æ–∂–∏, –æ–Ω–∏ –¥–ª—è –†–ê–ó–ù–´–• —Ç–∏–ø–æ–≤ –∑–¥–∞–Ω–∏–π/—Å–æ–æ—Ä—É–∂–µ–Ω–∏–π\n"
            "- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —É–¥–µ–ª—å–Ω—ã–π –≤–µ—Å, –Ω–∞–π–¥–∏ —Ä–∞–∑–¥–µ–ª '–£–¥–µ–ª—å–Ω—ã–µ –≤–µ—Å–∞' –≤ –ü–†–ê–í–ò–õ–¨–ù–û–ô —Ç–∞–±–ª–∏—Ü–µ\n"
            "- –û—Ç–≤–µ—á–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–ß–ù–´–ï —á–∏—Å–ª–∞ –∏–∑ –ü–†–ê–í–ò–õ–¨–ù–û–ô —Ç–∞–±–ª–∏—Ü—ã\n"
            "- –í–°–ï–ì–î–ê —É–∫–∞–∑—ã–≤–∞–π –Ω–æ–º–µ—Ä –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –≤–∑—è—Ç—ã –¥–∞–Ω–Ω—ã–µ"
        )
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (score) - –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏
        sorted_sources = sorted(sources, key=lambda x: x.get("score", 0), reverse=True)
        
        chunks_text = []
        for idx, source in enumerate(sorted_sources, start=1):
            tables_text = _format_tables(source.get("tables", []))
            section_path = source.get("section_path") or []
            title = source.get("title") or ""
            score = source.get("score", 0)
            
            chunk = f"\n{'='*60}\n–ò–°–¢–û–ß–ù–ò–ö {idx} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.3f})\n{'='*60}\n"
            if title:
                # –í—ã–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∂–∏—Ä–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏
                chunk += f"üìã –ù–ê–ó–í–ê–ù–ò–ï –¢–ê–ë–õ–ò–¶–´: {title}\n"
            if section_path:
                chunk += f"üìÅ –†–ê–ó–î–ï–õ: {' / '.join(section_path)}\n"
            chunk += f"üîó URL: {source.get('url', '')}\n\n"
            
            # –¢–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            text = source.get("text", "")
            if text:
                chunk += f"–¢–ï–ö–°–¢:\n{text}\n\n"
            
            # –¢–∞–±–ª–∏—Ü—ã
            if tables_text:
                chunk += f"{tables_text}\n"
            
            chunks_text.append(chunk)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å, —á—Ç–æ–±—ã –≤—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        query_lower = req.query.lower()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –¥–ª—è –ª—é–±—ã—Ö —Ç–∞–±–ª–∏—Ü)
        characteristics = []
        if "–æ–¥–Ω–æ—ç—Ç–∞–∂" in query_lower:
            characteristics.append("–æ–¥–Ω–æ—ç—Ç–∞–∂–Ω")
        if "–¥–≤—É—Ö—ç—Ç–∞–∂" in query_lower:
            characteristics.append("–¥–≤—É—Ö—ç—Ç–∞–∂–Ω")
        if "—Ç—Ä–µ—Ö—ç—Ç–∞–∂" in query_lower or "3-—ç—Ç–∞–∂" in query_lower:
            characteristics.append("—Ç—Ä–µ—Ö—ç—Ç–∞–∂–Ω")
        if "–±–µ–∑ –ø–æ–¥–≤–∞–ª–∞" in query_lower:
            characteristics.append("–±–µ–∑ –ø–æ–¥–≤–∞–ª–∞")
        if "—Å –ø–æ–¥–≤–∞–ª–æ–º" in query_lower:
            characteristics.append("—Å –ø–æ–¥–≤–∞–ª–æ–º")
        if "—Ç–∞–±–ª–∏—Ü–∞" in query_lower:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã
            table_match = re.search(r'—Ç–∞–±–ª–∏—Ü–∞\s*(\d+)', query_lower)
            if table_match:
                characteristics.append(f"—Ç–∞–±–ª–∏—Ü–∞ {table_match.group(1)}")
        
        # –ò—â–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        best_match_idx = None
        if characteristics:
            for idx, source in enumerate(sorted_sources):
                title_lower = (source.get("title") or "").lower()
                text_lower = (source.get("text") or "").lower()
                combined = f"{title_lower} {text_lower}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                matches = sum(1 for char in characteristics if char in combined)
                if matches == len(characteristics):
                    best_match_idx = idx
                    break
        
        user_prompt = (
            f"–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {req.query}\n"
        )
        
        if characteristics:
            user_prompt += f"\nüîç –ö–õ–Æ–ß–ï–í–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –í –í–û–ü–†–û–°–ï: {', '.join(characteristics)}\n"
            if best_match_idx is not None:
                user_prompt += f"‚úÖ –ù–ê–ô–î–ï–ù –¢–û–ß–ù–û –°–û–û–¢–í–ï–¢–°–¢–í–£–Æ–©–ò–ô –ò–°–¢–û–ß–ù–ò–ö: –ò—Å—Ç–æ—á–Ω–∏–∫ {best_match_idx + 1}\n"
            user_prompt += "‚ö†Ô∏è –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–∞–±–ª–∏—Ü—É, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –í–°–ï —ç—Ç–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏!\n"
        
        user_prompt += (
            f"\n–ò–°–ü–û–õ–¨–ó–£–ô –°–õ–ï–î–£–Æ–©–ò–ï –ò–°–¢–û–ß–ù–ò–ö–ò –î–õ–Ø –û–¢–í–ï–¢–ê (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏):\n"
            + "".join(chunks_text) + "\n" + "="*60 + "\n\n"
            "–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –í–´–ë–û–†–£ –ü–†–ê–í–ò–õ–¨–ù–û–ô –¢–ê–ë–õ–ò–¶–´ (–ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∫–æ –í–°–ï–ú —Ç–∞–±–ª–∏—Ü–∞–º):\n"
            "- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ - –ø–µ—Ä–≤—ã–π –æ–±—ã—á–Ω–æ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π\n"
            "- –í –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –ù–ï–°–ö–û–õ–¨–ö–û –ø–æ—Ö–æ–∂–∏—Ö —Ç–∞–±–ª–∏—Ü —Å –†–ê–ó–ù–´–ú–ò –Ω–æ–º–µ—Ä–∞–º–∏\n"
            "- –í–ù–ò–ú–ê–¢–ï–õ–¨–ù–û —Å—Ä–∞–≤–Ω–∏–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –≤–æ–ø—Ä–æ—Å–æ–º - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –¢–û–ß–ù–û —Å–æ–≤–ø–∞–¥–∞—Ç—å\n"
            "- –ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è —Ç–∏–ø –∑–¥–∞–Ω–∏—è/—Å–æ–æ—Ä—É–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–∞–±–ª–∏—Ü—É, "
            "–∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –≠–¢–ò –ñ–ï —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏\n"
            "- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã - –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —ç—Ç—É —Ç–∞–±–ª–∏—Ü—É\n"
            "- –ù–ï –ü–£–¢–ê–ô —Ä–∞–∑–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã - –¥–∞–∂–µ –ø–æ—Ö–æ–∂–∏–µ —Ç–∞–±–ª–∏—Ü—ã –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –†–ê–ó–ù–´–ú —Ç–∏–ø–∞–º –∑–¥–∞–Ω–∏–π/—Å–æ–æ—Ä—É–∂–µ–Ω–∏–π\n"
            "- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —É–¥–µ–ª—å–Ω—ã–π –≤–µ—Å, –Ω–∞–π–¥–∏ —Ä–∞–∑–¥–µ–ª '–£–¥–µ–ª—å–Ω—ã–µ –≤–µ—Å–∞' –≤ –ü–†–ê–í–ò–õ–¨–ù–û–ô —Ç–∞–±–ª–∏—Ü–µ\n"
            "- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–´–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –ü–†–ê–í–ò–õ–¨–ù–û–ô —Ç–∞–±–ª–∏—Ü—ã - –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —á–∏—Å–ª–∞\n"
            "- –í –æ—Ç–≤–µ—Ç–µ –í–°–ï–ì–î–ê —É–∫–∞–∑—ã–≤–∞–π –Ω–æ–º–µ—Ä –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –≤–∑—è—Ç—ã –¥–∞–Ω–Ω—ã–µ\n\n"
            "–û–¢–í–ï–¢–¨ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ü–†–ê–í–ò–õ–¨–ù–û–ô —Ç–∞–±–ª–∏—Ü—ã:"
        )

        gen_start = time.perf_counter()
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è —Å–¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ vLLM
            logger.info("Attempting to connect to vLLM at %s", settings.vllm_url)
            # vLLM —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ Authorization –¥–∞–∂–µ –µ—Å–ª–∏ –∫–ª—é—á "EMPTY"
            api_key = settings.vllm_api_key if settings.vllm_api_key else "EMPTY"
            headers = {"Authorization": f"Bearer {api_key}"}
            response = requests.post(
                f"{settings.vllm_url}/chat/completions",
                json={
                    "model": settings.vllm_model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": req.temperature,
                    "max_tokens": req.max_tokens,
                },
                headers=headers,
                timeout=120,
            )
            logger.info("vLLM response status: %s", response.status_code)
            response.raise_for_status()
            payload = response.json()
            answer = payload.get("choices", [{}])[0].get("message", {}).get("content", "")
            if not answer:
                answer = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
        except requests.exceptions.ConnectionError as exc:
            logger.error("vLLM connection error: %s (URL: %s)", exc, settings.vllm_url)
            error_msg = str(exc)
            answer_parts = [
                "‚ö†Ô∏è –°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ (vLLM) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.",
                f"–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫: {settings.vllm_url}",
                "",
                "–ù–∞–π–¥–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:",
                "",
            ]
            for idx, source in enumerate(sources[:3], start=1):
                title = source.get("title") or source.get("url", "")
                section = " / ".join(source.get("section_path") or [])
                answer_parts.append(f"{idx}. {title}")
                if section:
                    answer_parts.append(f"   –†–∞–∑–¥–µ–ª: {section}")
                answer_parts.append("")
            return {
                "answer": "\n".join(answer_parts),
                "sources": sources,
                "error": error_msg,
                "retrieval_duration": retrieval_duration,
                "generation_duration": 0.0,
            }
        except requests.exceptions.RequestException as exc:
            logger.error("vLLM request error: %s (URL: %s)", exc, settings.vllm_url)
            error_msg = str(exc)
            answer = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: {error_msg}"
            return {
                "answer": answer,
                "sources": sources,
                "error": error_msg,
                "retrieval_duration": retrieval_duration,
                "generation_duration": 0.0,
            }
        except Exception as exc:
            logger.error("vLLM processing error: %s", exc)
            return {
                "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏: {str(exc)}",
                "sources": sources,
                "error": str(exc),
                "retrieval_duration": retrieval_duration,
                "generation_duration": 0.0,
            }
        
        generation_duration = time.perf_counter() - gen_start
        logger.info(
            "rag duration retrieval=%.3fs generation=%.3fs query=%s",
            retrieval_duration,
            generation_duration,
            req.query,
        )

        return {
            "answer": answer.strip() if answer else "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.",
            "sources": sources,
            "retrieval_duration": retrieval_duration,
            "generation_duration": generation_duration,
            "error": None,
        }
    except Exception as exc:
        logger.error("RAG error: %s", exc, exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ RAG: {str(exc)}") from exc
